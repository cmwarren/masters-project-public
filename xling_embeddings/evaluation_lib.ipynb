{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import alignment_eval as al_evl\n",
    "import wiktionary_eval as wk_evl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alignment_eval_lang_pair(training_corpus, eval_set, sgns_dir, bmk_results, src_lang, tgt_lang):\n",
    "    \n",
    "    if eval_set.find('/') > -1:\n",
    "        eval_set_name = eval_set[0: eval_set.find('/')]\n",
    "    else:\n",
    "        eval_set_name = eval_set\n",
    "        \n",
    "    key = eval_set_name + '-' + src_lang + '-' + tgt_lang\n",
    "    print '\\tEvaluating: ' + key\n",
    "    bmk_results[key] = al_evl.alignment_eval('./' + training_corpus + '/' + sgns_dir + '/' + src_lang + '0.vecs',\n",
    "                                                      './' + training_corpus + '/' + sgns_dir + '/' + tgt_lang + '0.vecs',\n",
    "                                                      'eval_data/' + eval_set + '/alignment',\n",
    "                                                      'eval_data/' + eval_set + '/test.' + src_lang,\n",
    "                                                      'eval_data/' + eval_set + '/test.' + tgt_lang, False)\n",
    "    key = eval_set_name + '-' + tgt_lang + '-' + src_lang\n",
    "    print '\\tEvaluating: ' + key\n",
    "    bmk_results[key] = al_evl.alignment_eval('./' + training_corpus + '/' + sgns_dir + '/' + src_lang + '0.vecs',\n",
    "                                                      './' + training_corpus + '/' + sgns_dir + '/' + tgt_lang + '0.vecs',\n",
    "                                                      'eval_data/' + eval_set + '/alignment',\n",
    "                                                      'eval_data/' + eval_set + '/test.' + src_lang,\n",
    "                                                      'eval_data/' + eval_set + '/test.' + tgt_lang, True)\n",
    "    return bmk_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alignment_eval(training_corpus, sgns_dir):\n",
    "    bmk_results = dict()\n",
    "    bmk_results = alignment_eval_lang_pair(training_corpus, 'graca/enfr', sgns_dir, bmk_results, 'en', 'fr')\n",
    "    bmk_results = alignment_eval_lang_pair(training_corpus, 'graca/enes', sgns_dir, bmk_results, 'en', 'es')\n",
    "    bmk_results = alignment_eval_lang_pair(training_corpus, 'graca/enpt', sgns_dir, bmk_results, 'en', 'pt')\n",
    "    bmk_results = alignment_eval_lang_pair(training_corpus, 'hansards', sgns_dir, bmk_results, 'en', 'fr')\n",
    "    bmk_results = alignment_eval_lang_pair(training_corpus, 'lambert', sgns_dir, bmk_results, 'en', 'es')\n",
    "    bmk_results = alignment_eval_lang_pair(training_corpus, 'holmqvist', sgns_dir, bmk_results, 'en', 'sv')\n",
    "    if training_corpus != 'europarl':\n",
    "        bmk_results = alignment_eval_lang_pair(training_corpus, 'cakmak', sgns_dir, bmk_results, 'en', 'tr')\n",
    "    bmk_results = alignment_eval_lang_pair(training_corpus, 'mihalcea', sgns_dir, bmk_results, 'ro', 'en')\n",
    "    \n",
    "    return bmk_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wiktionary_eval_lang_pair(training_corpus, sgns_dir, bmk_results, src_lang, tgt_lang, b_include_oov=False, precision_at_N=1):\n",
    "    key = 'wiktionary-' + src_lang + '-' + tgt_lang\n",
    "    print '\\tEvaluating: ' + key\n",
    "    bmk_results[key] = wk_evl.wiktionary_eval('./' + training_corpus + '/' + sgns_dir + '/' + src_lang + '0.vecs', \n",
    "                                             './' + training_corpus + '/' + sgns_dir + '/' + tgt_lang + '0.vecs', \n",
    "                                             'eval_data/wiktionary/' + src_lang + '-' + tgt_lang + '-enwiktionary.txt',\n",
    "                                             b_reverse=False, b_include_oov=b_include_oov, precision_at_N=precision_at_N)\n",
    "    key = 'wiktionary-' + tgt_lang + '-' + src_lang\n",
    "    print '\\tEvaluating: ' + key\n",
    "    bmk_results[key] = wk_evl.wiktionary_eval('./' + training_corpus + '/' + sgns_dir + '/' + src_lang + '0.vecs', \n",
    "                                             './' + training_corpus + '/' + sgns_dir + '/' + tgt_lang + '0.vecs', \n",
    "                                             'eval_data/wiktionary/' + src_lang + '-' + tgt_lang + '-enwiktionary.txt',\n",
    "                                             b_reverse=True, b_include_oov=b_include_oov, precision_at_N=precision_at_N)\n",
    "    return bmk_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wiktionary_eval(training_corpus, sgns_dir, b_include_oov=False, lang_list=None, precision_at_N=1):\n",
    "    bmk_results = dict()\n",
    "    \n",
    "    if lang_list is None:\n",
    "        lang_list = ['ar','es','fi','fr','he','hu','pt','tr']\n",
    "    \n",
    "    for lang in lang_list:\n",
    "        if not(lang in ['ar','he','tr'] and training_corpus == 'europarl'):\n",
    "            bmk_results= wiktionary_eval_lang_pair(training_corpus, sgns_dir, bmk_results, \n",
    "                                                   'en', lang, b_include_oov=b_include_oov, precision_at_N=precision_at_N)\n",
    "    return bmk_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_sample_distribution(training_corpus, vecs_dir_prefix, b_alignment=True, b_wiktionary=True, \n",
    "                                 b_include_oov=False, lang_list=None, precision_at_N=1):\n",
    "    sample_dist = dict()\n",
    "    #if os.path.islink(training_corpus):\n",
    "    #    training_corpus = os.readlink(training_corpus)\n",
    "    for dirname in os.listdir(training_corpus):\n",
    "        if dirname.startswith(vecs_dir_prefix):\n",
    "            print 'Test sample: ' + dirname\n",
    "            if b_alignment:\n",
    "                alignment_results = alignment_eval(training_corpus, dirname)\n",
    "                for key, value in alignment_results.items():\n",
    "                    if key in sample_dist:\n",
    "                        sample_dist[key].append(value)\n",
    "                    else:\n",
    "                        sample_dist[key] = [value]\n",
    "            if b_wiktionary:\n",
    "                wiktionary_results = wiktionary_eval(training_corpus, dirname, b_include_oov, lang_list, precision_at_N)\n",
    "                for key, value in wiktionary_results.items():\n",
    "                    if key in sample_dist:\n",
    "                        sample_dist[key].append(value)\n",
    "                    else:\n",
    "                        sample_dist[key] = [value]\n",
    "    return sample_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_t_test(df_sample_dist, pop_mu):\n",
    "    sample_means = dict()\n",
    "    t_statistics = dict()\n",
    "    p_values = dict()\n",
    "    \n",
    "    for key in [col.encode('ascii', 'ignore') for col in df_sample_dist.columns.tolist()]:\n",
    "        sample = df_sample_dist[key]\n",
    "        [t_statistic, p_value] = ss.ttest_1samp(sample, pop_mu[key])\n",
    "        sample_means[key] = sample.mean()\n",
    "        t_statistics[key] = t_statistic\n",
    "        p_values[key] = p_value\n",
    "        \n",
    "    df_sample_dist.loc['mu-sample']=pd.DataFrame(sample_means, index=[0]).loc[0]\n",
    "    df_sample_dist.loc['mu-H0']=pd.DataFrame(pop_mu, index=[0]).loc[0]\n",
    "    df_sample_dist.loc['t-statistic']=pd.DataFrame(t_statistics, index=[0]).loc[0]\n",
    "    df_sample_dist.loc['p-value']=pd.DataFrame(p_values, index=[0]).loc[0]\n",
    "    \n",
    "    return df_sample_dist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
