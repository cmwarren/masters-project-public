{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append('hyperwords')\n",
    "from representations.embedding import Embedding\n",
    "import pprint\n",
    "import codecs\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative Analysis of Wikipedia Enriched Embeddings\n",
    "Arbitrarily select a set of 'bible' words and a set of 'modern' words, and investigate the top 10 nearest neighbour translations using the embeddings trained on the Bible enriched with Wikipedia data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bible_words = {'en-fr': [['man','woman','lamb','shepherd','sea'], \n",
    "                         ['homme','femme','agneau','berger','mer']],\n",
    "               'en-es': [['man','woman','lamb','shepherd','sea'], \n",
    "                         ['hombre','mujer','cordero','pastor','mar']],\n",
    "               'en-fi': [['man','woman','lamb','shepherd','sea'], \n",
    "                         ['mies','nainen','karitsa','paimen','meri']]}\n",
    "modern_words = {'en-fr': [['car','phone','film','newspaper','national'], \n",
    "                          ['voiture','téléphone','film','journal','nationale']],\n",
    "                'en-es': [['car','phone','film','newspaper','national'], \n",
    "                          ['coche','teléfono','película','periódico','nacional']],\n",
    "                'en-fi': [['car','phone','film','newspaper','national'], \n",
    "                          ['auto','puhelin','elokuva','sanomalehti','kansallinen']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_corpus = 'bible'\n",
    "enrich_corpus = 'twitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def translate_word(word, src_lang, trg_lang, training_corpus, sgns_dir):\n",
    "    src_vecs = './' + training_corpus + '/' + sgns_dir + '/' + src_lang + '0.vecs'\n",
    "    trg_vecs = './' + training_corpus + '/' + sgns_dir + '/' + trg_lang + '0.vecs'\n",
    "    Es = Embedding(src_vecs, True)\n",
    "    Et = Embedding(trg_vecs, True)\n",
    "    \n",
    "    vs = Es.represent(word)\n",
    "    scores = vs.dot(Et.m.T)\n",
    "    cands = []\n",
    "    idx_top10 = reversed(np.argsort(scores)[-10:])\n",
    "    for idx in idx_top10:\n",
    "        cands.append((Et.iw[idx], scores[idx]))\n",
    "    \n",
    "    return cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def translate_words_all_langs(word_dict, training_corpus, sgns_dir):\n",
    "    word_trans = dict()\n",
    "    for key,word_lists in word_dict.items():\n",
    "        src_lang = key[0:2]\n",
    "        trg_lang = key[3:]\n",
    "        for word in word_lists[0]:\n",
    "            trans_list = translate_word(word, src_lang, trg_lang, training_corpus, sgns_dir)\n",
    "            prefix_word = src_lang + '_' + word\n",
    "            if prefix_word not in word_trans:\n",
    "                word_trans[prefix_word] = dict()\n",
    "            word_trans[prefix_word][trg_lang] = trans_list\n",
    "        src_lang = key[3:]\n",
    "        trg_lang = key[0:2]\n",
    "        for word in word_lists[1]:\n",
    "            trans_list = translate_word(word, src_lang, trg_lang, training_corpus, sgns_dir)\n",
    "            prefix_word = src_lang + '_' + word\n",
    "            if prefix_word not in word_trans:\n",
    "                word_trans[prefix_word] = dict()\n",
    "            word_trans[prefix_word][trg_lang] = trans_list\n",
    "    return word_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pprint_lang_translations(langs):    \n",
    "    for lang, trans_list in langs.items():\n",
    "        print '\\t' + lang\n",
    "        trans_score_list = ''\n",
    "        for trans in trans_list:\n",
    "            trans_score_list = trans_score_list + '(' + trans[0] + ',' + \"{0:.3f}\".format(trans[1]) + '),'\n",
    "        print trans_score_list\n",
    "        print\n",
    "\n",
    "def pprint_translations(trans_dict, diff=False):\n",
    "    for word, langs in trans_dict.items():\n",
    "        print word + ':'\n",
    "        if diff:\n",
    "            print '  first:'\n",
    "            pprint_lang_translations(langs[0])\n",
    "            print '  second:'\n",
    "            pprint_lang_translations(langs[1])\n",
    "        else:\n",
    "            pprint_lang_translations(langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def diff_dict(first, second):\n",
    "    KEYNOTFOUND = '<KEYNOTFOUND>'\n",
    "    \n",
    "    diff = {}\n",
    "    for key in first.keys():\n",
    "        if (not second.has_key(key)):\n",
    "            diff[key] = (first[key], KEYNOTFOUND)\n",
    "        elif (first[key] != second[key]):\n",
    "            diff[key] = (first[key], second[key])\n",
    "    # Check all keys in second dict to find missing\n",
    "    for key in second.keys():\n",
    "        if (not first.has_key(key)):\n",
    "            diff[key] = (KEYNOTFOUND, second[key])\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bl_bible_word_trans = translate_words_all_langs(bible_words, training_corpus, 'sgns')\n",
    "pprint_translations(bl_bible_word_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bl_modern_word_trans = translate_words_all_langs(modern_words, training_corpus, 'sgns')\n",
    "pprint_translations(bl_modern_word_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "er_bible_word_trans = translate_words_all_langs(bible_words, training_corpus + '-' + enrich_corpus, 'sgns_enriched_0')\n",
    "pprint_translations(er_bible_word_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "er_modern_word_trans = translate_words_all_langs(modern_words, training_corpus + '-' + enrich_corpus, 'sgns_enriched_0')\n",
    "pprint_translations(er_modern_word_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate differences in nearest neighbour translations after enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pprint_translations(diff_dict(bl_bible_word_trans, er_bible_word_trans), diff=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequencies\n",
    "Investgate the frequencies of the arbitrarily selected 'bible' and 'modern' word lists in the embeddings that were trained on the Bible corpus alone, and when it was enriched with the Wikipedia corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_corpus_vocab(training_corpus, enrich_corpus):\n",
    "    corpus_vocab = dict()\n",
    "    if enrich_corpus is not None:\n",
    "        word_counts_file = './' + training_corpus + '-' + enrich_corpus + '/counts.words.vocab'\n",
    "    else:\n",
    "        word_counts_file = './' + training_corpus + '/counts.words.vocab'\n",
    "    with codecs.open(word_counts_file, 'r', encoding=\"utf8\", errors=\"replace\") as counts_file:\n",
    "        lines = [line.strip() for line in counts_file]\n",
    "        for line in lines:\n",
    "            count_entry = line.split(' ')\n",
    "            corpus_vocab[count_entry[0]] = int(count_entry[1])\n",
    "    return corpus_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_word_frequencies(word_lists, corpus_vocab):\n",
    "    for lang_pair, word_lists in word_lists.items():\n",
    "        src_lang = lang_pair[0:2]\n",
    "        trg_lang = lang_pair[3:]\n",
    "        for word in word_lists[0]:\n",
    "            enc_word = word.decode('utf-8')\n",
    "            if (src_lang + '0_' + enc_word) in corpus_vocab:\n",
    "                freq = corpus_vocab[src_lang + '0_' + enc_word]\n",
    "            else:\n",
    "                freq = 0\n",
    "            print src_lang + ': ' + enc_word + ': ' + str(freq)\n",
    "        for word in word_lists[1]:\n",
    "            enc_word = word.decode('utf-8')\n",
    "            if (trg_lang + '0_' + enc_word) in corpus_vocab:\n",
    "                freq = corpus_vocab[trg_lang + '0_' + enc_word]\n",
    "            else:\n",
    "                freq = 0\n",
    "            print trg_lang + ': ' + enc_word + ': ' + str(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corpus_vocab = build_corpus_vocab(training_corpus, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_word_frequencies(bible_words, corpus_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_word_frequencies(modern_words, corpus_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corpus_vocab = build_corpus_vocab(training_corpus, enrich_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_word_frequencies(bible_words, corpus_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_word_frequencies(modern_words, corpus_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat on a selection of words that have high enrich frequencies\n",
    "Based on the quantitative analysis of frequency distributions in 'enriched-quantitative-analysis.ipynb', create a list of words that appeared with high frequency in the Wikipedia enrich corpus, but low frequency in the Bible training corpus, and then do the same qualitative analysis as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_freq_enrich_words = {'en-fr': [['it\\'s','video','company','game','group'], \n",
    "                                    ['c\\'est','vidéo','société','jeu','groupe']],\n",
    "                          'en-es': [['game','national','video','team','season'], \n",
    "                                    ['partido','nacional','vídeo','equipo','temporada']],\n",
    "                          'en-fi': [['later','band','book','area','film'], \n",
    "                                    ['myöhemmin','yhtye','kirja','alue','elokuva']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_word_frequencies(high_freq_enrich_words, corpus_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "high_freq_word_trans_baseline = translate_words_all_langs(high_freq_enrich_words, training_corpus, 'sgns')\n",
    "pprint_translations(high_freq_word_trans_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "high_freq_word_trans_0 = translate_words_all_langs(high_freq_enrich_words, training_corpus + '-' + enrich_corpus, 'sgns_enriched_0')\n",
    "pprint_translations(high_freq_word_trans_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pprint_translations(diff_dict(high_freq_word_trans_baseline, high_freq_word_trans_0), diff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#high_freq_word_trans_1 = translate_words_all_langs(high_freq_enrich_words, training_corpus + '-' + enrich_corpus, 'sgns_enriched_1')\n",
    "#pprint_translations(high_freq_word_trans_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#high_freq_word_trans_2 = translate_words_all_langs(high_freq_enrich_words, training_corpus + '-' + enrich_corpus, 'sgns_enriched_2')\n",
    "#pprint_translations(high_freq_word_trans_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pprint_translations(diff_dict(high_freq_word_trans_0, high_freq_word_trans_1), diff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pprint_translations(diff_dict(high_freq_word_trans_0, high_freq_word_trans_2), diff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "months_words = {'en-fr': [['january','february','march','april','may','june','july','august','september','october','november','december'], \n",
    "                          ['janvier','fevrier','mars','avril','mai','juin','juillet','aout','septembre','octobre','novembre','decembre']],\n",
    "                'en-es': [['january','february','march','april','may','june','july','august','september','october','november','december'],\n",
    "                          ['enero','febrero','marzo','abril','mayo','junio','julio','agosto','septiembre','octubre','noviembre','diciembre']],\n",
    "                'en-fi': [['january','february','march','april','may','june','july','august','september','october','november','december'],\n",
    "                          ['tammikuu','helmikuu','maaliskuu','huhtikuu','toukokuu','kesäkuu','heinäkuu','elokuu','syyskuu','lokakuu','marraskuu','joulukuu']]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_word_frequencies(months_words, corpus_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "month_word_trans = translate_words_all_langs(months_words, training_corpus, 'sgns')\n",
    "pprint_translations(month_word_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "month_word_trans = translate_words_all_langs(months_words, training_corpus + '-' + enrich_corpus, 'sgns_enriched_0')\n",
    "pprint_translations(month_word_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
