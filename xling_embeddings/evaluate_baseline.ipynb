{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Baseline Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Baseline Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-write the steps in Levy's evaluate_bible.sh and evaluate_europarl.sh in Python, so that we can analyse the  sampling distribution of accuracies resulting from mupltiple randomly seeded embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ./evaluation_lib.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vecs_dir_prefix = 'sgns_baseline'\n",
    "training_corpus = 'bible'\n",
    "results_spreadsheet = training_corpus + '_eval.xlsx'\n",
    "precision_at_N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dist = evaluate_sample_distribution(training_corpus, vecs_dir_prefix, lang_list=['es','fi','fr'], precision_at_N=precision_at_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(sample_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = df_results.mean()\n",
    "sample_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance Testing\n",
    "Perform a two-tailed hypothesis test (Student's t-test) at the 5% significance level on the test results sample, versus the true population of possible results of the evaluation benchmarks. In this case, the true population is an infinite set of all the possible test results that could be collected for these benchmarks.\n",
    "<br><br>\n",
    "\\begin{equation}\n",
    "H_0: \\mu_{pop} \\approx \\mu_{Levy} \\\\\n",
    "H_a: \\mu_{pop} \\neq \\mu_{Levy}\n",
    "\\end{equation}\n",
    "i.e. <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;H<sub>0</sub>: The published results of Levy et al's experiments are a good approximation of the true population mean<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;H<sub>a</sub>: Either the published results of Levy et al's experiments are not a good approximation of the true population mean, or my recreation of their experiment differs in some significant way\n",
    "<br>\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{p-value} = P(\\text{observed experimental results or a more extreme outcome } | H_0 \\text{ true})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taken from Levy et al 2017 - table 3 - results column \"Multilingual SID-SGNS\"\n",
    "# The \"Multilingual SID-SGNS\" approach seems to be the one implemented in the sample code.\n",
    "\n",
    "levy_mu = {\n",
    " 'cakmak-en-tr': 0.2404,\n",
    " 'cakmak-tr-en': 0.2945,\n",
    " 'graca-en-es': 0.4893,\n",
    " 'graca-en-fr': 0.4433,\n",
    " 'graca-en-pt': 0.4047,\n",
    " 'graca-es-en': 0.5015,\n",
    " 'graca-fr-en': 0.4632,\n",
    " 'graca-pt-en': 0.4151,\n",
    " 'hansards-en-fr': 0.4091,\n",
    " 'hansards-fr-en': 0.4302,\n",
    " 'holmqvist-en-sv': 0.2737,\n",
    " 'holmqvist-sv-en': 0.3195,\n",
    " 'lambert-en-es': 0.2989,\n",
    " 'lambert-es-en': 0.3049,\n",
    " 'mihalcea-en-ro': 0.2514,\n",
    " 'mihalcea-ro-en': 0.2753,\n",
    " 'wiktionary-ar-en': 0.3082,\n",
    " 'wiktionary-en-ar': 0.1605,\n",
    " 'wiktionary-en-es': 0.3509,\n",
    " 'wiktionary-en-fi': 0.1591,\n",
    " 'wiktionary-en-fr': 0.3304,\n",
    " 'wiktionary-en-he': 0.1448,\n",
    " 'wiktionary-en-hu': 0.2482,\n",
    " 'wiktionary-en-pt': 0.4058,\n",
    " 'wiktionary-en-tr': 0.2437,\n",
    " 'wiktionary-es-en': 0.3868,\n",
    " 'wiktionary-fi-en': 0.2584,\n",
    " 'wiktionary-fr-en': 0.3893,\n",
    " 'wiktionary-he-en': 0.2403,\n",
    " 'wiktionary-hu-en': 0.3372,\n",
    " 'wiktionary-pt-en': 0.4376,\n",
    " 'wiktionary-tr-en': 0.3080\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sig_results = calc_t_test(df_results, levy_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sig_results.to_pickle('./' + training_corpus + '/df_sig_results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(results_spreadsheet)\n",
    "df_sig_results.to_excel(writer, vecs_dir_prefix)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve previously saved baseline results from file, execute next block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sig_results = pd.read_pickle('./' + training_corpus + '/df_sig_results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_filtered_sig_results = df_sig_results.filter(['wiktionary-en-es',\n",
    "                  'wiktionary-en-fi',\n",
    "                  'wiktionary-en-fr',\n",
    "                  'wiktionary-es-en',\n",
    "                  'wiktionary-fi-en',\n",
    "                  'wiktionary-fr-en'], \n",
    "                 axis=1)\n",
    "df_filtered_sig_results.columns = ['en-es','en-fi','en-fr','es-en','fi-en','fr-en']\n",
    "df_filtered_sig_results = df_filtered_sig_results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_filtered_sig_results.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
