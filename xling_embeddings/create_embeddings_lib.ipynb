{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from hyperwords import bible2pairs as b2p\n",
    "from hyperwords import counts2vocab as c2v\n",
    "from hyperwords import text2numpy_nonewline as t2np\n",
    "import sys\n",
    "import codecs\n",
    "import os\n",
    "import subprocess\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pairs(path):\n",
    "    # python2 hyperwords/bible2pairs.py 2 ${1} > ./${1}/pairs\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    pairs_path = path + 'pairs'\n",
    "    if os.path.exists(pairs_path):\n",
    "        os.remove(pairs_path)\n",
    "    f_pairs = open(pairs_path, 'a')\n",
    "    b2p.bible2pairs(2, path, f_output=f_pairs)\n",
    "    f_pairs.close()\n",
    "    \n",
    "    return [path, pairs_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_counts(path, pairs_path):\n",
    "    # scripts/pairs2counts.sh ./${1}/pairs > ./${1}/counts\n",
    "\n",
    "    # Re-implement pairs2counts.sh in python:\n",
    "    #     sort -T ~/. $1 | uniq -c\n",
    "\n",
    "    # sort -T ~/. [file]\n",
    "    #    Sorts the contents of a text file, line by line; \n",
    "    #    -T Use current dir for temporaries, not $TMPDIR or /tmp.\n",
    "    # uniq -c\n",
    "    #    Reports or filters out repeated lines in a file; \n",
    "    #    -c Prefix lines with a number representing how many times they occurred.\n",
    "\n",
    "    f_pairs = open(pairs_path, 'r')\n",
    "    vocab_counter = collections.Counter()\n",
    "    print('Starting reading pairs into vocab counter')\n",
    "    for line in f_pairs.readlines():\n",
    "        vocab_counter.update([line])\n",
    "    f_pairs.close()\n",
    "    print('Finished reading pairs into vocab counter')\n",
    "\n",
    "    counts_path = path + 'counts'\n",
    "    if os.path.exists(counts_path):\n",
    "        os.remove(counts_path)\n",
    "        \n",
    "    print('Starting outputting vocab counter to file')\n",
    "    f_counts = open(counts_path, 'a')\n",
    "    for item, count in sorted(vocab_counter.items()):\n",
    "        f_counts.write('      ' + str(count) + ' ' + item)\n",
    "    f_counts.close()\n",
    "    print('Finished outputting vocab counter to file')\n",
    "    \n",
    "    return counts_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_sgns_dir(path, sgns_dir, indx):\n",
    "    # mkdir ./${1}/sgns\n",
    "    sgns_path = path + sgns_dir + '_' + str(indx) + '/'\n",
    "    if not os.path.exists(sgns_path):\n",
    "        os.makedirs(sgns_path)\n",
    "    return sgns_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_word2vecf(path, sgns_path):\n",
    "    # word2vecf/word2vecf \n",
    "    #    -train ./${1}/pairs \n",
    "    #    -pow 0.75 \n",
    "    #    -cvocab ./${1}/counts.contexts.vocab \n",
    "    #    -wvocab ./${1}/counts.words.vocab \n",
    "    #    -dumpcv ./${1}/sgns/contexts \n",
    "    #    -output ./${1}/sgns/words \n",
    "    #    -threads 4 \n",
    "    #    -negative 1 \n",
    "    #    -iters 100 \n",
    "    #    -size 500\n",
    "    \n",
    "    counts_contexts_path = path + 'counts.contexts.vocab'\n",
    "    counts_words_path = path + 'counts.words.vocab'\n",
    "    sgns_contexts_path = sgns_path + 'contexts'\n",
    "    sgns_words_path = sgns_path + 'words'\n",
    "    sgns_log_path = sgns_path + 'log'\n",
    "\n",
    "    args = ['word2vecf/word2vecf', '-train', pairs_path, '-pow', '0.75', \n",
    "            '-cvocab', counts_contexts_path, '-wvocab', counts_words_path,\n",
    "           '-dumpcv', sgns_contexts_path, '-output', sgns_words_path,\n",
    "           '-threads', '4', '-negative', '1', '-iters', '100', '-size', '500']\n",
    "\n",
    "    # subprocess.check_call(args, *, stdin=None, stdout=None, stderr=None, shell=False)\n",
    "    # subprocess.Popen(args, bufsize=0, executable=None, stdin=None, stdout=None, stderr=None, \n",
    "    #    preexec_fn=None, close_fds=False, shell=False, cwd=None, env=None, universal_newlines=False, \n",
    "    #    startupinfo=None, creationflags=0)\n",
    "    print('Calling word2vecf with args: ' + str(args))\n",
    "    with open(sgns_log_path, 'a') as log_out:\n",
    "        subprocess.check_call(args, stdout=log_out, shell=False)\n",
    "    \n",
    "    return [sgns_contexts_path, sgns_words_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vecs_to_numpy(sgns_path):\n",
    "    # for v in `ls ./${1}/sgns/*.vecs`; do python2 hyperwords/text2numpy_nonewline.py ${v}; done\n",
    "    for filename in os.listdir(sgns_path):\n",
    "        if filename.endswith(\".vecs\"):\n",
    "            [npy_file, vocab_file] = t2np.text2numpy_nonewline(sgns_path + '/' + filename)\n",
    "            print [npy_file, vocab_file]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
